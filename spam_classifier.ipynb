{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam Text Classification using kNN Classifier\n",
    "\n",
    "Data Source:\n",
    "https://www.kaggle.com/team-ai/spam-text-message-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Category</th>\n",
       "      <th>Message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Category                                            Message\n",
       "0      ham  Go until jurong point, crazy.. Available only ...\n",
       "1      ham                      Ok lar... Joking wif u oni...\n",
       "2     spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      ham  U dun say so early hor... U c already then say...\n",
       "4      ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('spam.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization and Stemming\n",
    "\n",
    "The goal of both stemming and lemmatization is to reduce inflectional forms and sometimes derivationally related forms of a word to a common base form.\n",
    "\n",
    "The difference between these methods are:\n",
    "- **Lemmatization** usually refers to doing things properly with the use of a vocabulary and morphological analysis of words, normally aiming to remove inflectional endings only and to return the base or dictionary form of a word, which is known as the lemma\n",
    "- **Stemming** usually refers to a crude heuristic process that chops off the ends of words in the hope of achieving this goal correctly most of the time, and often includes the removal of derivational affixes.\n",
    "\n",
    "source: https://nlp.stanford.edu/IR-book/html/htmledition/stemming-and-lemmatization-1.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lemmatizer\n",
    "lem = []\n",
    "import nltk\n",
    "# nltk.download('wordnet') # need to donwload this for the first time\n",
    "lemma = nltk.wordnet.WordNetLemmatizer()\n",
    "for i in df.Message:\n",
    "    j = lemma.lemmatize(i)\n",
    "    lem.append(j)\n",
    "\n",
    "#stemmer\n",
    "stem = []\n",
    "sno = nltk.stem.SnowballStemmer('english')\n",
    "for i in lem:\n",
    "    j = sno.stem(i)\n",
    "    stem.append(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "This process converts a dataset of text documents to a matrix of token counts (number)\n",
    "<br/>\n",
    "<img src=\"image/vector.jpeg\" width=400  />\n",
    "source: https://towardsdatascience.com/another-twitter-sentiment-analysis-with-python-part-4-count-vectorizer-b3f4944e51b5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "(5572, 244)\n"
     ]
    }
   ],
   "source": [
    "# nltk.download('stopwords') # need to donwload this for the first time\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(min_df=35, stop_words = stopwords.words('english'))\n",
    "\n",
    "cv_X = cv.fit_transform(stem)\n",
    "fea = cv.get_feature_names()\n",
    "mat = cv_X.toarray()\n",
    "print(mat)\n",
    "print(mat.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "TF-IDF (term frequencyâ€“inverse document frequency) is a method used for calculating the weight of each word based on its frequency in all documents.\n",
    "<br/>\n",
    "<img src=\"image/tfidf.png\" width=400  />\n",
    "source: https://www.researchgate.net/publication/319996754_Finding_discriminative_and_interpretable_patterns_in_sequences_of_surgical_activities/figures?lo=1&utm_source=google&utm_medium=organic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of        10  100  1000  150p   16   18  1st   50  500  account  ...     world  \\\n",
      "0     0.0  0.0   0.0   0.0  0.0  0.0  0.0  0.0  0.0      0.0  ...  0.552623   \n",
      "1     0.0  0.0   0.0   0.0  0.0  0.0  0.0  0.0  0.0      0.0  ...  0.000000   \n",
      "2     0.0  0.0   0.0   0.0  0.0  0.0  0.0  0.0  0.0      0.0  ...  0.000000   \n",
      "3     0.0  0.0   0.0   0.0  0.0  0.0  0.0  0.0  0.0      0.0  ...  0.000000   \n",
      "4     0.0  0.0   0.0   0.0  0.0  0.0  0.0  0.0  0.0      0.0  ...  0.000000   \n",
      "...   ...  ...   ...   ...  ...  ...  ...  ...  ...      ...  ...       ...   \n",
      "5567  0.0  0.0   0.0   0.0  0.0  0.0  0.0  0.0  0.0      0.0  ...  0.000000   \n",
      "5568  0.0  0.0   0.0   0.0  0.0  0.0  0.0  0.0  0.0      0.0  ...  0.000000   \n",
      "5569  0.0  0.0   0.0   0.0  0.0  0.0  0.0  0.0  0.0      0.0  ...  0.000000   \n",
      "5570  0.0  0.0   0.0   0.0  0.0  0.0  0.0  0.0  0.0      0.0  ...  0.000000   \n",
      "5571  0.0  0.0   0.0   0.0  0.0  0.0  0.0  0.0  0.0      0.0  ...  0.000000   \n",
      "\n",
      "      would  www  xxx   ya  yeah  year  yes  yet  yup  \n",
      "0       0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  0.0  \n",
      "1       0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  0.0  \n",
      "2       0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  0.0  \n",
      "3       0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  0.0  \n",
      "4       0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  0.0  \n",
      "...     ...  ...  ...  ...   ...   ...  ...  ...  ...  \n",
      "5567    0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  0.0  \n",
      "5568    0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  0.0  \n",
      "5569    0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  0.0  \n",
      "5570    0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  0.0  \n",
      "5571    0.0  0.0  0.0  0.0   0.0   0.0  0.0  0.0  0.0  \n",
      "\n",
      "[5572 rows x 244 columns]>\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidfconverter = TfidfTransformer()\n",
    "mat = tfidfconverter.fit_transform(mat).toarray()\n",
    "X = pd.DataFrame(mat, columns = fea)\n",
    "\n",
    "#categorical mapping\n",
    "di = {'ham': 1, 'spam' : 0}\n",
    "y = df.Category.map(di)\n",
    "\n",
    "print(X.head)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity\n",
    "\n",
    "Cosine Similarity is aparameter which shows the similarity level between sentences/documents using the cosine principle of a particular angle\n",
    "<br/>\n",
    "<img src=\"image/cosine.png\" width=400  />\n",
    "source: https://www.researchgate.net/publication/255181106_Xlang_ISCIS/figures?lo=1&utm_source=google&utm_medium=organic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "sim = cosine_similarity(X, X)\n",
    "print(sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "#stratify is to maintain \"y\" portion in train/test dataset\n",
    "X_train, X_test, y_train, y_test=train_test_split(X,y, test_size=0.2, stratify = y, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "    \n",
    "#fit and predict\n",
    "knn.fit(X_train, y_train) #fit model to training data\n",
    "y_pred_train = knn.predict(X_train) #predict model to training data\n",
    "y_pred = knn.predict(X_test) #predict model to testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.85      0.91       598\n",
      "           1       0.98      1.00      0.99      3859\n",
      "\n",
      "    accuracy                           0.98      4457\n",
      "   macro avg       0.97      0.92      0.95      4457\n",
      "weighted avg       0.98      0.98      0.98      4457\n",
      "\n",
      "testing data classification report: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.83      0.88       149\n",
      "           1       0.97      0.99      0.98       966\n",
      "\n",
      "    accuracy                           0.97      1115\n",
      "   macro avg       0.96      0.91      0.93      1115\n",
      "weighted avg       0.97      0.97      0.97      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print('training data classification report: \\n' + classification_report(y_train,y_pred_train))\n",
    "print('testing data classification report: \\n' +classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
